{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L3-1: Implementing Decision Trees.ipynb","provenance":[{"file_id":"1pvuT_hYrs0BTOCmeh4x8vbm2TcnYKYSE","timestamp":1613716958458},{"file_id":"19G_dWJF2LhrdgNDpxcrIOnBZwi12rToT","timestamp":1603479044703}],"collapsed_sections":[],"authorship_tag":"ABX9TyNaqCm+3IPufMGkT20WpNGA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-EgjzQKvNt0v"},"source":["#L3-1: Implementing Decision Trees"]},{"cell_type":"markdown","metadata":{"id":"R70382R1v2U_"},"source":["Hello and welcome! In this lab, we will implement decision trees. Let's get started."]},{"cell_type":"markdown","metadata":{"id":"nfNbOA15QmND"},"source":["# Class Enjoyment Data"]},{"cell_type":"markdown","metadata":{"id":"NXietRfvSlTD"},"source":["The first thing we need is data! And the most primitive way to get the data in (which is practical only if you have a really small dataset) is to enter it manually and that's what we do to enter the class enjoyment data discussed in the class:"]},{"cell_type":"markdown","metadata":{"id":"Aoznqz1cRvCE"},"source":["## Data Entry"]},{"cell_type":"markdown","metadata":{"id":"UCsECencS3mq"},"source":["Butr let's load the packages we are going to need for data processing first:"]},{"cell_type":"code","metadata":{"id":"5RTQeDRkQu2w"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TEBHzRkpS-qH"},"source":["Then, we can enter our data:"]},{"cell_type":"code","metadata":{"id":"pHFjluoilqnx"},"source":["data = [['y', 'y', 'n', 'y', 'n', '+2'],\n","        ['y', 'y', 'n', 'y', 'n', '+2'],\n","        ['n', 'y', 'n', 'n', 'n', '+2'],\n","        ['n', 'n', 'n', 'y', 'n', '+2'],\n","        ['n', 'y', 'y', 'n', 'y', '+2'],\n","        ['y', 'y', 'n', 'n', 'n', '+1'],\n","        ['y', 'y', 'n', 'y', 'n', '+1'],\n","        ['n', 'y', 'n', 'y', 'n', '+1'],\n","        ['n', 'n', 'n', 'n', 'y',  '0'],\n","        ['y', 'n', 'n', 'y', 'y',  '0'],\n","        ['n', 'y', 'n', 'y', 'n',  '0'],\n","        ['y', 'y', 'y', 'y', 'y',  '0'],\n","        ['y', 'y', 'y', 'n', 'y', '-1'],\n","        ['n', 'n', 'y', 'y', 'n', '-1'],\n","        ['n', 'n', 'y', 'n', 'y', '-1'],\n","        ['y', 'n', 'y', 'n', 'y', '-1'],\n","        ['n', 'n', 'y', 'y', 'n', '-2'],\n","        ['n', 'y', 'y', 'n', 'y', '-2'],\n","        ['y', 'n', 'y', 'n', 'n', '-2'],\n","        ['y', 'n', 'y', 'n', 'y', '-2']\n","       ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i6si-bK6TElL"},"source":["...and create a pandas DataFrame out of it:"]},{"cell_type":"code","metadata":{"id":"mSWtphfsTJmr"},"source":["column_names = ['Easy', 'AI', 'Systems', 'Theory', 'Morning', 'Rating']\n","\n","df = pd.DataFrame(data, columns=column_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2BSTSAmWTJul"},"source":["Let's view what we created:"]},{"cell_type":"code","metadata":{"id":"kHnZjzospezg"},"source":["display(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UsMNLiySTPRQ"},"source":["Looks nice!\n","\n","There is a caveat though: many ML algorithms only work if we have purely numeric data, so everything has to be converted to numbers. We often take some processing steps on data before feeding it to machine learning algorithms and these steps are usually called *data pre-processing*."]},{"cell_type":"markdown","metadata":{"id":"ZILWjdk0Q9W5"},"source":["## Processing Features"]},{"cell_type":"markdown","metadata":{"id":"xbhEmT5vTy1j"},"source":["We will use the object [make_column_transformer](https://https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) defined in the compose submodule od scikit-learn and objects [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) and [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) from scikit-learn's preprocessing submodule to help us with converting binary features that we have in the data to number values."]},{"cell_type":"code","metadata":{"id":"8TvzpiUw_67S"},"source":["from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import OrdinalEncoder, LabelEncoder"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uOL9Nc9zVq02"},"source":["Now, we feed columns we want converted to these objects in order to convert the categorical features (which Boolean features are a kind of) to numbers. That is acoomplished below by using make_column_transformer and OrdinalEncoder functions. We also want to convert class labels to be positive integer numbers and we do that with LabelEncoder. Read the documentation for these function to get a grasp of different parameters and details of what is done."]},{"cell_type":"code","metadata":{"id":"g4c39KFxtZ-U"},"source":["feature_names = column_names[:-1]\n","label_name = column_names[-1]\n","\n","X_preprocess = make_column_transformer((OrdinalEncoder(), feature_names), \n","                                       remainder='drop')\n","y_preprocess = LabelEncoder()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqH5F2TxRB4E"},"source":["## Data Matrices"]},{"cell_type":"markdown","metadata":{"id":"1M84F5JBYLSr"},"source":["Next, we create the actual converted data matrices (including the label vector) using the preprocessor objects we just created:"]},{"cell_type":"code","metadata":{"id":"EHyQw30x0Q8b"},"source":["X = X_preprocess.fit_transform(df[feature_names])\n","y = y_preprocess.fit_transform(df[label_name])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkRL9vyAaIdy"},"source":["..and here is the data as NumPy arrays:"]},{"cell_type":"code","metadata":{"id":"uY_rqFrO2k9H"},"source":["display(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6V9bei2cRFJG"},"source":["## The Decision Tree"]},{"cell_type":"markdown","metadata":{"id":"JJA-dsnSRbRO"},"source":["### Making"]},{"cell_type":"markdown","metadata":{"id":"sFQRE-5yaPku"},"source":["We use the decision tree classifier class implemented in scikit-learn, [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) implemented in the tree submodule of scikit-learn."]},{"cell_type":"code","metadata":{"id":"haLqttC4_9ll"},"source":["from sklearn.tree import DecisionTreeClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2FbcRIScCt6"},"source":["We define an object (instance) from the class and let's call it `dtree`:"]},{"cell_type":"code","metadata":{"id":"mFvWbURmcNlI"},"source":["dtree = DecisionTreeClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZkBMYR2vcNyh"},"source":["Now, we can 'fit' the data to our classifier, which basically means training your classifier and finding the QuAM. We use the [fit](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) method of the `dtree` object of DecisionTreeClassifer class we just created:"]},{"cell_type":"code","metadata":{"id":"GLNQYIlJRSVk"},"source":["dtree.fit(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sOgZh-9scgnJ"},"source":["Now, we have our decision tree classifier QuAM ready. Now, we can make predictions on new points with our QuAM.\n","\n","Let's first define some new points:"]},{"cell_type":"code","metadata":{"id":"N--uD9PkOGU1"},"source":["X_new = np.array([[1., 1., 1., 1., 0.],\n","                  [0., 0., 0., 1., 1.]\n","                 ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QMMibXh43MIx"},"source":["Now, we can use our QuAM to 'predict' labels for new data points using the [predict](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict) method of the `dtree` object of the DecisionTreeClassifier class we trained (fitted):"]},{"cell_type":"code","metadata":{"id":"H7_pep70OagM"},"source":["yhat_new = dtree.predict(X_new)\n","display(yhat_new)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZoLUh34W3j16"},"source":["We want to display class names as they are shown in the original data and we do that by using the inverse_transform method of the preprocessing object we transformed the labels with. We can get a list of class labels this way:"]},{"cell_type":"code","metadata":{"id":"vv0Yw8yb3m3i"},"source":["class_names = y_preprocess.inverse_transform(np.arange(y.max() + 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XsNde2iZ36ve"},"source":["Now, we can see the original label names for our predictions:"]},{"cell_type":"code","metadata":{"id":"PQc5skMB3_tr"},"source":["display(class_names[yhat_new])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0TelvnwrRUET"},"source":["### Visualizing"]},{"cell_type":"markdown","metadata":{"id":"q25ORUTkcmDw"},"source":["Let's visualize our tree. We will use the program [Graphviz](https://graphviz.org/) (and the Python package [graphviz](https://pypi.org/project/graphviz/), which provides a Python interface of Graphviz) to generate the visualization. Iorder to do that, we have to generate an approprite kind of description, called DOT format, generated using the [export_graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html) function implmented in scikit-learn's tree submodule, of the decision tree we just created  and convert the DOT formatted data to graph with Graphviz. Then, we can display our graph. Let us import the required packages first:"]},{"cell_type":"code","metadata":{"id":"AI5q7pMXRY1H"},"source":["from sklearn.tree import export_graphviz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MV5lZQpUhlA3"},"source":["Then, we can use the packages we imported to visualize:"]},{"cell_type":"code","metadata":{"id":"8IPMYEwpKmF6"},"source":["import graphviz\n","from sklearn.tree import export_graphviz\n","dot_data = export_graphviz(dtree,\n","                           out_file=None, \n","                           class_names=class_names.tolist(),\n","                           feature_names=feature_names,  \n","                           filled=True,\n","                           rounded=True,  \n","                           special_characters=True,\n","                           rotate=True)  \n","\n","display(graphviz.Source(dot_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRUxQpjU6xra"},"source":["We can also do a (maybe) more informative kind of visualization, showing us the distribution of points in different regions in the tree.\n","\n","For that, we need a package [dtreeviz](https://github.com/parrt/dtreeviz) that is not included in Colab environment by default, so we install it:"]},{"cell_type":"code","metadata":{"id":"RVPo9MJHMukM"},"source":["!pip install dtreeviz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECebKyPe7LDH"},"source":["Now, we use the dtreeviz object in the trees submodule of dtreeviz to create the visualization:"]},{"cell_type":"code","metadata":{"id":"cJZ7EXHIywHg"},"source":["from dtreeviz.trees import dtreeviz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpdl0FepKmOT"},"source":["viz = dtreeviz(tree_model=dtree,\n","               x_data=X,\n","               y_data=y,\n","               target_name=label_name,\n","               feature_names=np.array(feature_names),\n","               class_names=class_names.tolist(),\n","               orientation ='LR',\n","               scale=2.0)              \n","display(viz)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S21Op9gl738s"},"source":["Now, we can also visualize what happens when we want to make a prediction for a new data point:"]},{"cell_type":"code","metadata":{"id":"arTxwIWzPAwz"},"source":["viz = dtreeviz(tree_model=dtree,\n","               x_data=X,\n","               y_data=y,\n","               target_name=label_name,\n","               feature_names=np.array(feature_names),\n","               class_names=class_names.tolist(),\n","               orientation ='LR',\n","               X=X_new[0],\n","               scale=2.0)              \n","display(viz)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aREcQ-ih7cqW"},"source":["We use the explain_prediction_path function in the trees submodule of dtreeviz to generate an explanation of the prediction generated by the decision tree:"]},{"cell_type":"code","metadata":{"id":"DyWNG28W7dtM"},"source":["from dtreeviz.trees import explain_prediction_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0o6RemZ8Pagt"},"source":["print(explain_prediction_path(tree_model=dtree,\n","                              x=X_new[0],\n","                              feature_names=np.array(feature_names),\n","                              explanation_type=\"plain_english\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y-SL3l6G8XDL"},"source":["We can also see how important the different features were in predicting what the QuAM did:"]},{"cell_type":"code","metadata":{"id":"jmVtmmMi2se5"},"source":["print(explain_prediction_path(tree_model=dtree,\n","                              x=X_new[0],\n","                              feature_names=np.array(feature_names),\n","                              explanation_type=\"sklearn_default\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"20gOJx_FhswK"},"source":["Finally (for this data), here is a dynamic visualization showing how the tree is built, step-by-step:"]},{"cell_type":"code","metadata":{"cellView":"form","id":"h9aZYKhly2h_"},"source":["#@title Interactive Visualizer: How is the tree built? { run: \"auto\" }\n","\n","slider = 12 #@param {type:\"slider\", min:2, max:15, step:1}\n","display(slider)\n","\n","dtree = DecisionTreeClassifier(max_leaf_nodes=slider)\n","dtree.fit(X, y)\n","\n","dot_data = export_graphviz(dtree,\n","                           out_file=None, \n","                           class_names=class_names.tolist(),\n","                           feature_names=feature_names,  \n","                           filled=True,\n","                           rounded=True,  \n","                           special_characters=True,\n","                           rotate=True)  \n","\n","graph = graphviz.Source(dot_data)  \n","display(graph)\n","\n","viz = dtreeviz(tree_model=dtree,\n","               x_data=X,\n","               y_data=y,\n","               target_name=label_name,\n","               feature_names=np.array(feature_names),\n","               class_names=class_names.tolist(),\n","               scale=2.0)              \n","display(viz)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-b9b9tLRlKa"},"source":["# The Iris Dataset"]},{"cell_type":"markdown","metadata":{"id":"cBAjuByJh42s"},"source":["Let's try building a decision tree classifier on a real-world data. Let's use the Iris dataset we talked about in the lab for module 2:"]},{"cell_type":"markdown","metadata":{"id":"ShDe0vEFSyQC"},"source":["http://archive.ics.uci.edu/ml/datasets/iris"]},{"cell_type":"markdown","metadata":{"id":"1kDLyEEwR5Zy"},"source":["## Getting the data"]},{"cell_type":"markdown","metadata":{"id":"q_htCVgQiULy"},"source":["Again, we use the requests package and the get function therein as well as a [StringIO](https://docs.python.org/3/library/io.html?highlight=stringio#io.StringIO) object (a part of Python's [io](https://docs.python.org/3/library/io.html) package) to fetch the data off web and convert it to a text string object:"]},{"cell_type":"code","metadata":{"id":"UUouzM-K83Lv"},"source":["from requests import get\n","from io import StringIO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E5XdH15hicGN"},"source":["Now, we can read the data and put it in a DataFrame:"]},{"cell_type":"code","metadata":{"id":"q4fkxpbu8wMW"},"source":["url=\"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n","file_bytes = get(url).content\n","data_file = StringIO(file_bytes.decode('utf-8'))\n","\n","feature_names_iris=[\"Sepal Length (cm)\", \"Sepal Width (cm)\", \"Petal Length (cm)\", \"Petal Width (cm)\"]\n","label_name_iris = \"Class\"\n","\n","column_names_iris = feature_names_iris + [label_name_iris]\n","\n","iris_df = pd.read_csv(data_file, names=feature_names_iris + [label_name_iris])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1X4Is8kwihDF"},"source":["This is the data:"]},{"cell_type":"code","metadata":{"id":"T7yC_2e49Ac1"},"source":["display(iris_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFwoqaLeSC1K"},"source":["## (Building and Visualizing)"]},{"cell_type":"markdown","metadata":{"id":"QQKeImmEiuC8"},"source":["We can build a deciion tree with all four features, however, here, we want to visualize the space where the data lies in (aprt form the tree) and to do that we should have data that has less than (or equal to) 3 dimensions."]},{"cell_type":"code","metadata":{"id":"FVbJae_f8ssb","cellView":"form"},"source":["#@title\n","# X_iris = iris_df[feature_names_iris].values\n","# y_iris = iris_df[label_name_iris].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWbGFkXX91yn","cellView":"form"},"source":["#@title\n","# dtree_iris = DecisionTreeClassifier()\n","# dtree_iris.fit(X_iris, y_iris)\n","\n","# dot_data = StringIO()\n","# export_graphviz(dtree_iris, \n","#                 out_file=dot_data, \n","#                 class_names=np.unique(y_iris),\n","#                 feature_names=feature_names,\n","#                 filled=True,\n","#                 rounded=True,\n","#                 special_characters=True)\n","# graph = graph_from_dot_data(dot_data.getvalue())\n","# Image(graph.create_png())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6y_4s2Q_SMEP"},"source":["## Choosing Two Features"]},{"cell_type":"markdown","metadata":{"id":"FUH-A95Ei8Jo"},"source":["We do a 2D visualization first. So, let's choose two features:"]},{"cell_type":"code","metadata":{"id":"5UR58CtDLnle"},"source":["feature_names_2t=[\"Petal Length (cm)\", \"Petal Width (cm)\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVdagUuZjAq2"},"source":["...and get NumPy arrays for the data:"]},{"cell_type":"code","metadata":{"id":"MSaMibFSLspa"},"source":["y_preprocess_iris = LabelEncoder()\n","\n","X_iris_2t = iris_df[feature_names_2t].values\n","y_iris = y_preprocess_iris.fit_transform(iris_df[label_name_iris].values)\n","\n","class_names_iris = y_preprocess_iris.inverse_transform(np.arange(y_iris.max() + 1)).astype(str).tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oF1ASXuKjE5_"},"source":["Now, we can build the decisioon tree:"]},{"cell_type":"code","metadata":{"id":"Q3lmoHc5Ly9h"},"source":["dtree_iris_2t = DecisionTreeClassifier()\n","dtree_iris_2t.fit(X_iris_2t, y_iris)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eFHrVN94jI06"},"source":["Now, we can visualize the tree:"]},{"cell_type":"code","metadata":{"id":"MYtqTUUkL78s"},"source":["dot_data = export_graphviz(dtree_iris_2t,\n","                           out_file=None, \n","                           class_names=class_names_iris,\n","                           feature_names=feature_names_2t,  \n","                           filled=True,\n","                           rounded=True,  \n","                           special_characters=True,\n","                           rotate=True)  \n","\n","display(graphviz.Source(dot_data))\n","\n","viz = dtreeviz(tree_model=dtree_iris_2t,\n","               x_data=X_iris_2t,\n","               y_data=y_iris,\n","               target_name=label_name_iris,\n","               feature_names=np.array(feature_names_2t),\n","               class_names=class_names_iris,\n","               orientation ='LR',\n","               scale=2.0)              \n","display(viz)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GF1usWtvSWP4"},"source":["## Surfaces and Regions"]},{"cell_type":"markdown","metadata":{"id":"U13_1ycjjMIN"},"source":["Now, let's try to visualize the space created by a decision tree classifier. For that we use plotly. Here, we are using an older function and you may be able to accomplish the same thing with plotly express, but this workd for now:"]},{"cell_type":"code","metadata":{"id":"Hl9fBKuqWehL"},"source":["import plotly.graph_objects as go"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayVFVj1GdpjT","cellView":"form"},"source":["#@title\n","# fig = go.Figure()\n","\n","# fig.add_trace(go.Scatter(x=X_iris_2t[:, 0],\n","#                         y=X_iris_2t[:, 1],\n","#                         mode='markers',\n","#                         marker=dict(color=yn_iris_2t,\n","#                                     colorscale=colorscale,\n","#                                     size=10\n","#                                    )\n","#                        )\n","#              )\n","# fig.update_layout(xaxis=dict(range=[0, 7], gridwidth=1, zeroline=True, zerolinecolor='LightGrey', nticks=8), \n","#                  yaxis=dict(range=[0, 3], gridwidth=1, zeroline=True, zerolinecolor='LightGrey', nticks=3), \n","#                  plot_bgcolor=\"white\"\n","#                 )\n","# fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UyaX-gHzj_nt"},"source":["Then, we can visualize the space using a scatterplot and a heatmap overlaiod on each other:"]},{"cell_type":"code","metadata":{"id":"-NX1JAj7WTrk"},"source":["fig = go.Figure()\n","\n","colorscale = [(0.00,   \"red\"), (0.32,   \"red\"), \n","              (0.33, \"green\"), (0.66, \"green\"), \n","              (0.67,  \"blue\"), (1.00,  \"blue\")\n","             ]\n","             \n","fig.add_trace(go.Scatter(x=X_iris_2t[:, 0],\n","                        y=X_iris_2t[:, 1],\n","                        mode='markers',\n","                        marker=dict(color=y_iris,\n","                                    colorscale=colorscale,\n","                                    size=10\n","                                   )\n","                       )\n","             )\n","\n","red_tr =   \"rgba(255,   0,   0, 0.25)\" \n","green_tr = \"rgba(  0, 255,   0, 0.25)\"\n","blue_tr =  \"rgba(  0,   0, 255, 0.25)\"\n","colorscale_tr = [(0.00,   red_tr), (0.32,   red_tr), \n","                 (0.33, green_tr), (0.66, green_tr), \n","                 (0.67,  blue_tr), (1.00,  blue_tr)\n","                ]\n","\n","x_iris_2t_mins = X_iris_2t.min(axis=0)\n","x_iris_2t_maxs = X_iris_2t.max(axis=0)\n","\n","x_iris_2t1_vis1 = np.linspace(x_iris_2t_mins[0], x_iris_2t_maxs[0], 60)\n","x_iris_2t2_vis1 = np.linspace(x_iris_2t_mins[1], x_iris_2t_maxs[1], 25)\n","\n","XX_iris_2t1_vis, XX_iris_2t2_vis = np.meshgrid(x_iris_2t1_vis1, x_iris_2t2_vis1)\n","\n","x_iris_2t1_vis = XX_iris_2t1_vis.flatten()\n","x_iris_2t2_vis = XX_iris_2t2_vis.flatten()\n","\n","X_iris_2t_vis = np.c_[x_iris_2t1_vis, x_iris_2t2_vis]\n","\n","yn_iris_2t_vis = dtree_iris_2t.predict(X_iris_2t_vis)\n","\n","YYn_iris_2t_vis = yn_iris_2t_vis.reshape(XX_iris_2t1_vis.shape)\n","\n","fig.add_trace(go.Heatmap(x=x_iris_2t1_vis1,\n","                        y=x_iris_2t2_vis1,\n","                        z=YYn_iris_2t_vis,\n","                        zmin=yn_iris_2t_vis.min(),\n","                        zmax=yn_iris_2t_vis.max(),  \n","                        colorscale=colorscale_tr\n","                       )\n","            )\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2NCDSh0SbDM"},"source":["## Three Features: 3D"]},{"cell_type":"markdown","metadata":{"id":"yuOyq_dOkCiU"},"source":["We can do the same thing with 3 features and in 3D space:"]},{"cell_type":"code","metadata":{"id":"QpfPGC6T-NaW"},"source":["feature_names_3t = [\"Sepal Length (cm)\", \"Petal Length (cm)\", \"Petal Width (cm)\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWraInWn-NoD"},"source":["X_iris_3t = iris_df[feature_names_3t].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-m1UGe3-RWd"},"source":["dtree_iris_3t = DecisionTreeClassifier()\n","dtree_iris_3t.fit(X_iris_3t, y_iris)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVcY0UIK-GvD"},"source":["dot_data = export_graphviz(dtree_iris_3t,\n","                           out_file=None, \n","                           class_names=class_names_iris,\n","                           feature_names=feature_names_3t,  \n","                           filled=True,\n","                           rounded=True,  \n","                           special_characters=True,\n","                           rotate=True)  \n","\n","display(graphviz.Source(dot_data))\n","\n","viz = dtreeviz(tree_model=dtree_iris_3t,\n","               x_data=X_iris_3t,\n","               y_data=y_iris,\n","               target_name=label_name_iris,\n","               feature_names=np.array(feature_names_3t),\n","               class_names=class_names_iris,\n","               orientation ='LR',\n","               scale=2.0)              \n","display(viz)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6mdNatKhkb_H"},"source":["Now, we will use a 3D scatter plot:"]},{"cell_type":"code","metadata":{"id":"fvU6BySRi--o"},"source":["fig = go.Figure()\n","fig.add_trace(go.Scatter3d(x=X_iris_3t[:, 0],\n","                          y=X_iris_3t[:, 1],\n","                          z=X_iris_3t[:, 2],\n","                          mode='markers',\n","                          marker=dict(color=y_iris,\n","                                      colorscale=colorscale,\n","                                      size=5\n","                                     )\n","                         )\n","             )\n","\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PnZEQdkzkhGh"},"source":["Let's visualize the space as well by overlaying a 3D volume plot on top:"]},{"cell_type":"code","metadata":{"id":"9ZKUMulvfXCk"},"source":["x_iris_3t_mins = X_iris_3t.min(axis=0)\n","x_iris_3t_maxs = X_iris_3t.max(axis=0)\n","\n","x_iris_3t1_vis = np.linspace(x_iris_3t_mins[0], x_iris_3t_maxs[0], 20)\n","x_iris_3t2_vis = np.linspace(x_iris_3t_mins[1], x_iris_3t_maxs[1], 20)\n","x_iris_3t3_vis = np.linspace(x_iris_3t_mins[2], x_iris_3t_maxs[2], 20)\n","\n","XX_iris_3t1_vis, XX_iris_3t2_vis, XX_iris_3t3_vis = \\\n","  np.meshgrid(x_iris_3t1_vis, x_iris_3t2_vis, x_iris_3t3_vis)\n","\n","x_iris_3t1_vis = XX_iris_3t1_vis.flatten()\n","x_iris_3t2_vis = XX_iris_3t2_vis.flatten()\n","x_iris_3t3_vis = XX_iris_3t3_vis.flatten()\n","\n","X_iris_3t_vis = np.c_[x_iris_3t1_vis, x_iris_3t2_vis, x_iris_3t3_vis]\n","\n","yn_iris_3t_vis = dtree_iris_3t.predict(X_iris_3t_vis)\n","\n","fig.add_trace(go.Volume(x=x_iris_3t1_vis,\n","                       y=x_iris_3t2_vis,\n","                       z=x_iris_3t3_vis,\n","                       value=yn_iris_3t_vis,\n","                       isomin=0,\n","                       isomax=2,\n","                       opacity=0.25,\n","                       surface_count=20,\n","                       colorscale=colorscale,\n","                       showscale=False\n","                      )\n","            )\n","\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qBgPiws7krr-"},"source":["Finally, here, let's see how the space is split iteratively when building a decision tree using a dynamic visualization:"]},{"cell_type":"code","metadata":{"cellView":"form","id":"rBpXZ4NEDPvo"},"source":["#@title Interactive Visualizer { run: \"auto\" }\n","\n","slider = 10 #@param {type:\"slider\", min:2, max:10, step:1}\n","display(slider)\n","\n","dtree_iris_3tl = DecisionTreeClassifier(max_leaf_nodes=slider)\n","dtree_iris_3tl.fit(X_iris_3t, y_iris)\n","\n","dot_data = export_graphviz(dtree_iris_3tl,\n","                           out_file=None, \n","                           class_names=class_names_iris,\n","                           feature_names=feature_names_3t,  \n","                           filled=True,\n","                           rounded=True,  \n","                           special_characters=True,\n","                           rotate=True)  \n","\n","viz = dtreeviz(tree_model=dtree_iris_3tl,\n","               x_data=X_iris_3t,\n","               y_data=y_iris,\n","               target_name=label_name_iris,\n","               feature_names=np.array(feature_names_3t),\n","               class_names=class_names_iris,\n","               orientation ='LR',\n","               scale=2.0)\n","              \n","yn_iris_3tl_vis = dtree_iris_3tl.predict(X_iris_3t_vis)\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatter3d(x=X_iris_3t[:, 0],\n","                          y=X_iris_3t[:, 1],\n","                          z=X_iris_3t[:, 2],\n","                          mode='markers',\n","                          marker=dict(color=y_iris,\n","                                      colorscale=colorscale,\n","                                      size=5\n","                                     )\n","                         )\n","             )\n","fig.add_trace(go.Volume(x=x_iris_3t1_vis,\n","                       y=x_iris_3t2_vis,\n","                       z=x_iris_3t3_vis,\n","                       value=yn_iris_3tl_vis,\n","                       isomin=0,\n","                       isomax=2,\n","                       opacity=0.25,\n","                       surface_count=20,\n","                       colorscale=colorscale,\n","                       showscale=False\n","                      )\n","            )\n","\n","fig.show()\n","display(graphviz.Source(dot_data))\n","display(viz)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j2t2_Mw4Sino"},"source":["## The Heart Disease Dataset"]},{"cell_type":"markdown","metadata":{"id":"YM1pvxApk7uo"},"source":["Now, let's use a more \"real\" real-world dataset as well. We use the Heart Disease dataset from UCI dataset repository:"]},{"cell_type":"markdown","metadata":{"id":"-3Q06ZF6SrkZ"},"source":["https://archive.ics.uci.edu/ml/datasets/Heart+Disease"]},{"cell_type":"markdown","metadata":{"id":"AEn6urXHS4dg"},"source":["## Getting Data"]},{"cell_type":"markdown","metadata":{"id":"unO_KUkNlJq8"},"source":["We get the data like before. This data is composed of four different sources, eahc stored in a separate file:"]},{"cell_type":"code","metadata":{"id":"Lz7yCMwbYgH8"},"source":["url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/cleveland.data\"\n","file_bytes = get(url).content"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6k7RekpHlMmB"},"source":["We can now try to display the file as text:"]},{"cell_type":"code","metadata":{"id":"ryx48QntYgy3"},"source":["data_file = StringIO(file_bytes.decode('utf-8'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYnSyElrlS-G"},"source":["As you can see that fails. This is because there are errors in the file; a very common thing that happens with real-world datasets. So, let's ignore the errors and display the file:"]},{"cell_type":"code","metadata":{"id":"BxZThZ80YjK5"},"source":["data_file = StringIO(file_bytes.decode('utf-8', 'ignore'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HxRtWnVGllVl"},"source":["Now, we can see the file:"]},{"cell_type":"code","metadata":{"id":"hsf8ghy3GhDQ"},"source":["print(data_file.getvalue())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QGdPHziCYYEE"},"source":["url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/hungarian.data\"\n","file_bytes = get(url).content\n","data_file = StringIO(file_bytes.decode('utf-8', 'ignore'))\n","print(data_file.getvalue())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHwVb5GkYYJG"},"source":["url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/long-beach-va.data\"\n","file_bytes = get(url).content\n","data_file = StringIO(file_bytes.decode('utf-8', 'ignore'))\n","print(data_file.getvalue())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5-MtjBSYYUh"},"source":["url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/switzerland.data\"\n","file_bytes = get(url).content\n","data_file = StringIO(file_bytes.decode('utf-8', 'ignore'))\n","print(data_file.getvalue())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MiwbHDZ3l8nz"},"source":["As you can see the separator in the file is not commas but rather spaces. We need to consider that when converting the data to a DataFrame. Let's load the 'Cleveland' data:"]},{"cell_type":"code","metadata":{"id":"-RgMnNGuV9O2"},"source":["url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n","file_bytes = get(url).content\n","data_file = StringIO(file_bytes.decode('utf-8'))\n","\n","feature_names_heart=[\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"]\n","label_name_heart = \"num\"\n","\n","column_names_heart = feature_names_heart + [label_name_heart]\n","\n","heart_df = pd.read_csv(data_file, names=feature_names_heart + [label_name_heart])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8DahRFmcmtEh"},"source":["...and display:"]},{"cell_type":"code","metadata":{"id":"K8pfWuFsWUPS"},"source":["display(heart_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U2Ij7Mj2m3_V"},"source":["Let's try to see if we have missing values:"]},{"cell_type":"code","metadata":{"id":"7OL2DL5QZ-ub"},"source":["rows_with_missing = heart_df.eq(\"?\").any(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OCFLD5ARm73m"},"source":["The warning happens because some columns are numbers and can't be trivially compared with the string `\"?\"`.Let's see where our missing values happen:"]},{"cell_type":"code","metadata":{"id":"s5f0me3JI0vL"},"source":["display(rows_with_missing)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X9T6cBJpnPn7"},"source":["Let's view the actual rows:"]},{"cell_type":"code","metadata":{"id":"wG1I_GBtbhp3"},"source":["display(heart_df[rows_with_missing])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VND2mKHGnU2A"},"source":["Now, let us do data exploration:"]},{"cell_type":"code","metadata":{"id":"3JqxSK5Ib_Bv"},"source":["heart_df_nm = heart_df[~rows_with_missing]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffXWOoJBd8YF"},"source":["import plotly.express as px"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kIhz47rd_Dm"},"source":["fig = px.scatter_matrix(heart_df_nm, dimensions=feature_names_heart, color=label_name_heart)\n","fig.update_layout(\n","    autosize=False,\n","    width=13 * 100,\n","    height=13 * 100,\n","    margin=dict(l=0, r=0, t=0, b=0)\n",")\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h9o5LUN2Nedw"},"source":["## Splitting the data"]},{"cell_type":"code","metadata":{"id":"QhkiDCd3gpYm"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lRSxV1tIJnZ6"},"source":["display(X_heart_nm, y_heart_nm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3K_5LhnNhKj"},"source":["X_heart_nm = heart_df_nm[feature_names_heart].values\n","y_heart_nm = heart_df_nm[label_name_heart].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTxYmxbfNufq"},"source":["X_heart_nm_train, X_heart_nm_test, y_heart_nm_train, y_heart_nm_test = \\\n","  train_test_split(X_heart_nm, y_heart_nm, test_size=0.33)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yaEUCmidS959"},"source":["## Building a Tree"]},{"cell_type":"markdown","metadata":{"id":"4aYbY4IpnZNz"},"source":["Now, we can build a decision tree:"]},{"cell_type":"code","metadata":{"id":"lX02e-2acwFS"},"source":["dtree_heart_nm = DecisionTreeClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z_WWZ52AdOTE"},"source":["dtree_heart_nm.fit(X_heart_nm_train, y_heart_nm_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCvWB_uzc12a"},"source":["class_names_heart = np.unique(heart_df_nm[label_name_heart])\n","\n","dot_data = export_graphviz(dtree_heart_nm,\n","                           out_file=None, \n","                           class_names=class_names_heart.astype(\"str\").tolist(),\n","                           feature_names=feature_names_heart,  \n","                           filled=True,\n","                           rounded=True,  \n","                           special_characters=True,\n","                           rotate=True)  \n","\n","display(graphviz.Source(dot_data))\n","\n","# viz = dtreeviz(tree_model=dtree_heart_nm,\n","#                x_data=X_heart_nm.astype(\"float\"),\n","#                y_data=y_heart_nm,\n","#                target_name=label_name_heart,\n","#                feature_names=np.array(feature_names_heart),\n","#                class_names=class_names_heart.tolist(),\n","#                orientation ='LR',\n","#                scale=2.0)              \n","# display(viz)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eh5xrV4wndMD"},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{"id":"cC5cbeFHgPDC"},"source":["A basic evaluation metric we have for the task of classification was a *confusion matrix*. A confusion matrix is basically a table which shows the number of datapoints that were classified as a certain class, where they really belonged to (maybe) another class. In short, in shows us the number of correct classifications and misclassifications. Again we use scikit-learn's implementation for showing confusion matrices:"]},{"cell_type":"code","metadata":{"id":"u77Xxb1dfgBO"},"source":["from sklearn.metrics import confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"benZFUEdgR0J"},"source":["First, let's classify (predict) using our QuAM we just built. The QuAM object has a method called `predict` (like it had a `fit` method to train and find the QuAM) which classifies the data."]},{"cell_type":"code","metadata":{"id":"gvqMPd9Hexmn"},"source":["yhat_heart_nm_train = dtree_heart_nm.predict(X_heart_nm_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-QMovlBgo1N"},"source":["Now, we can build the confusion matrix:"]},{"cell_type":"code","metadata":{"id":"so_ty4jefTYx"},"source":["cm_heart_nm_train = confusion_matrix(y_heart_nm_train, yhat_heart_nm_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhlPgNEJgUpR"},"source":["...and display it:"]},{"cell_type":"code","metadata":{"id":"wb9ak0c-frhl"},"source":["display(cm_heart_nm_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rHEoKF5gXSf"},"source":["scikit-learn has another function, [plot_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) implemented in the same metrics submodule, which gives you the confucion matrix in a nice representation"]},{"cell_type":"code","metadata":{"id":"DIoc9BFzh2MW"},"source":["from sklearn.metrics import plot_confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ua5vNc7HgaSQ"},"source":["Which shows a heatmap-like table:"]},{"cell_type":"code","metadata":{"id":"8B8B9jeUiGYS"},"source":["plot_confusion_matrix(dtree_heart_nm, X_heart_nm_train, y_heart_nm_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VhHSJQJ0hrhT"},"source":["Now, let's do the confusion matrix for test data as well:"]},{"cell_type":"code","metadata":{"id":"HkA040vch05h"},"source":["plot_confusion_matrix(dtree_heart_nm, X_heart_nm_test, y_heart_nm_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"82YCr1lmh7l_"},"source":["What do you see?"]},{"cell_type":"markdown","metadata":{"id":"FPyra2Zoh9RX"},"source":["Let's also do a classification evaluation summary on both training and test data as well:"]},{"cell_type":"code","metadata":{"id":"mvqwrduQh3bC"},"source":["from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FLqm4priQVW"},"source":["print(\"Results on training data:\")\n","print(classification_report(y_heart_nm_train, yhat_heart_nm_train))\n","print()\n","yhat_heart_nm_test = dtree_heart_nm.predict(X_heart_nm_test)\n","print(\"Results on test data:\")\n","print(classification_report(y_heart_nm_test, yhat_heart_nm_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WpeiFAWaK8a_"},"source":["## The learning curve"]},{"cell_type":"markdown","metadata":{"id":"ywNW9thTjv3f"},"source":["To study the bias and variance of our model, let's do a learning curve as well:"]},{"cell_type":"code","metadata":{"id":"W72R-GwOjwsC"},"source":["from sklearn.model_selection import learning_curve"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssAF4y7lpB4e"},"source":["data_sizes, training_scores, validation_scores = \\\n","  learning_curve(DecisionTreeClassifier(), X_heart_nm_train, \\\n","                 y_heart_nm_train, cv=10, scoring='accuracy', \\\n","                 train_sizes=np.linspace(0.01, 1.0, 51))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0l9jG4nj_Kf"},"source":["training_mean = training_scores.mean(axis=1) \n","training_standard_deviation = training_scores.std(axis=1) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NABsYpd_kBaI"},"source":["validation_mean = validation_scores.mean(axis=1) \n","validation_standard_deviation = validation_scores.std(axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNRugekokEEn"},"source":["import plotly.graph_objects as go"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jcwql_gzkG7F"},"source":["fig = go.Figure()\n","\n","fig.add_trace(go.Scatter(x=data_sizes, \n","                        y=training_mean,\n","                        mode='lines',\n","                        name='Training',\n","                        line=dict(color='red')))\n","fig.add_trace(go.Scatter(x=data_sizes, \n","                        y=training_mean - training_standard_deviation,\n","                        mode='lines',\n","                        name='Training lower bound',\n","                        line=dict(width=0, color='red'),\n","                        showlegend=False))\n","fig.add_trace(go.Scatter(x=data_sizes, \n","                        y=training_mean + training_standard_deviation,\n","                        mode='lines',\n","                        name='Training upper bound',\n","                        line=dict(width=0, color='red'),\n","                        fill='tonexty',\n","                        fillcolor='rgba(255, 0, 0, 0.3)',\n","                        showlegend=False))\n","\n","fig.add_trace(go.Scatter(x=data_sizes, \n","                        y=validation_mean,\n","                        mode='lines',\n","                        name='Validation',\n","                        line=dict(color='blue')))\n","fig.add_trace(go.Scatter(x=data_sizes, \n","                        y=validation_mean - validation_standard_deviation,\n","                        mode='lines',\n","                        name='Validation lower bound',\n","                        line=dict(width=0, color='blue'),\n","                        showlegend=False))\n","fig.add_trace(go.Scatter(x=data_sizes, \n","                        y=validation_mean + validation_standard_deviation,\n","                        mode='lines',\n","                        name='Validation upper bound',\n","                        line=dict(width=0, color='blue'),\n","                        fill='tonexty',\n","                        fillcolor='rgba(0, 0, 255, 0.3)',\n","                        showlegend=False))\n","\n","fig.update_layout(title='Learning curve',\n","                 xaxis_title='Dataset size',\n","                 yaxis_title='Accuracy')\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HanNkobTxquO"},"source":["What's to note here is not only that we are consistently in the high bias range, but also that we have high variance!"]},{"cell_type":"markdown","metadata":{"id":"7A4vWnYgCS8I"},"source":["That's all Folks!"]}]}